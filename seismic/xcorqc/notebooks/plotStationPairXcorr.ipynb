{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.dates\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import dateutil\n",
    "from dateutil import rrule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "package_root = os.path.abspath('../../..')\n",
    "if package_root not in sys.path:\n",
    "    sys.path.append(package_root)\n",
    "from seismic.ASDFdatabase import FederatedASDFDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import obspy\n",
    "from seismic.xcorqc.analytic_plot_utils import distance\n",
    "from netCDF4 import Dataset as NCDataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for plotting\n",
    "from textwrap import wrap\n",
    "from scipy import signal\n",
    "from matplotlib.backends.backend_pdf import PdfPages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seismic.xcorqc.xcorr_station_clock_analysis import plot_xcorr_file_clock_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = FederatedASDFDataSet.FederatedASDFDataSet(\"/g/data/ha3/Passive/SHARED_DATA/Index/asdf_files.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_correlator_config(nc_file):\n",
    "    '''Read the correlator settings used for given nc file.\n",
    "    '''\n",
    "    folder, fname = os.path.split(nc_file)\n",
    "    base, _ = os.path.splitext(fname)\n",
    "    base_parts = base.split('.')\n",
    "    if len(base_parts) > 4:\n",
    "        timestamp = '.'.join(base_parts[4:7])\n",
    "        config_filename = '.'.join(['correlator', timestamp, 'cfg'])\n",
    "        config_file = os.path.join(folder, config_filename)\n",
    "        if os.path.exists(config_file):\n",
    "            settings_df = pd.read_csv(config_file, sep=':', names=['setting', 'value'],\n",
    "                                      index_col=0, skiprows=1, skipinitialspace=True,\n",
    "                                      squeeze=True, converters={'setting': str.strip})\n",
    "            title_tag = '({}-{} Hz)'.format(settings_df['--fmin'], settings_df['--fmax'])\n",
    "        else:\n",
    "            print('WARNING: Settings file {} not found!'.format(config_file))\n",
    "            settings_df = None\n",
    "            title_tag = ''\n",
    "    else:\n",
    "        settings_df = None\n",
    "        title_tag = ''\n",
    "\n",
    "    return settings_df, title_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_WINDOW = 600 # +/-\n",
    "# TIME_WINDOW = 300 # +/-\n",
    "# TIME_WINDOW = 120 # +/-\n",
    "# SNR_THRESHOLD = 10\n",
    "SNR_THRESHOLD = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NCFILE_PATH = '/g/data/ha3/am7399/shared/xcorr/AU/QIS_Warramunga'\n",
    "# NCFILE_PATH = '/home/547/am7399/am7399/shared/xcorr/7X/MAx_MAy'\n",
    "\n",
    "SRC_FILES = glob.glob(os.path.join(NCFILE_PATH, '*.nc'))\n",
    "\n",
    "print(\"Found {} .nc files\".format(len(SRC_FILES)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "save_plots = True\n",
    "underlay_rcf_xcorr = False\n",
    "\n",
    "pbar = tqdm(total=len(SRC_FILES))\n",
    "found_preexisting = False\n",
    "failed_files = []\n",
    "for src_file in SRC_FILES:\n",
    "    _, base_file = os.path.split(src_file)\n",
    "    pbar.set_description(base_file)\n",
    "    pbar.update()\n",
    "    # Extract timestamp from nc filename if available\n",
    "    settings, title_tag = read_correlator_config(src_file)\n",
    "    \n",
    "    assert os.path.exists(src_file), \"File {} not found!\".format(src_file)\n",
    "\n",
    "    try:\n",
    "        if save_plots:\n",
    "            basename, _ = os.path.splitext(src_file)\n",
    "            png_file = basename + \".png\"\n",
    "            # If png file already exists and has later timestamp than src_file, then skip it.\n",
    "            if os.path.exists(png_file):\n",
    "                src_file_time = os.path.getmtime(src_file)\n",
    "                png_file_time = os.path.getmtime(png_file)\n",
    "                if png_file_time > src_file_time:\n",
    "                    tqdm.write(\"PNG file {} is more recent than source file {}, skipping!\".format(\n",
    "                               os.path.split(png_file)[1], os.path.split(src_file)[1]))\n",
    "                    found_preexisting = True\n",
    "                    continue\n",
    "            plot_xcorr_file_clock_analysis(src_file, ds, TIME_WINDOW, SNR_THRESHOLD, png_file=png_file,\n",
    "                                           show=False, underlay_rcf_xcorr=underlay_rcf_xcorr,\n",
    "                                           title_tag=title_tag, settings=settings)\n",
    "        else:\n",
    "            plot_xcorr_file_clock_analysis(src_file, ds, TIME_WINDOW, SNR_THRESHOLD, \n",
    "                                           underlay_rcf_xcorr=underlay_rcf_xcorr, title_tag=title_tag,\n",
    "                                           settings=settings)\n",
    "        if gc.garbage:\n",
    "            tqdm.write(\"WARNING: {} items of uncollectable garbage\".format(len(gc.garbage)))\n",
    "\n",
    "    except Exception as e:\n",
    "        tqdm.write(\"ERROR processing file {}\".format(src_file))\n",
    "        failed_files.append((src_file, e.message))\n",
    "        \n",
    "pbar.close()\n",
    "\n",
    "if failed_files:\n",
    "    print(\"The following files experienced errors:\")\n",
    "    for f, e in failed_files:\n",
    "        print(\" File: \" + f)\n",
    "        print(\"Error: \" + e)\n",
    "\n",
    "if found_preexisting:\n",
    "    print(\"Some files were skipped because pre-existing matching png files were up-to-date.\\n\"\n",
    "          \"Remove png files to force regeneration.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
