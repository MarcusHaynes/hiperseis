{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "package_root = os.path.abspath('../../..')\n",
    "if package_root not in sys.path:\n",
    "    sys.path.append(package_root)\n",
    "from seismic.ASDFdatabase import FederatedASDFDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = FederatedASDFDataSet.FederatedASDFDataSet(\"/g/data/ha3/Passive/SHARED_DATA/Index/asdf_files.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_correlator_config(nc_file):\n",
    "    '''Read the correlator settings used for given nc file.\n",
    "    '''\n",
    "    import pandas as pd\n",
    "    \n",
    "    folder, fname = os.path.split(nc_file)\n",
    "    base, _ = os.path.splitext(fname)\n",
    "    base_parts = base.split('.')\n",
    "    if len(base_parts) > 4:\n",
    "        timestamp = '.'.join(base_parts[4:-1])\n",
    "        config_filename = '.'.join(['correlator', timestamp, 'cfg'])\n",
    "        config_file = os.path.join(folder, config_filename)\n",
    "        if os.path.exists(config_file):\n",
    "            settings_df = pd.read_csv(config_file, sep=':', names=['setting', 'value'],\n",
    "                                      index_col=0, skiprows=1, skipinitialspace=True,\n",
    "                                      squeeze=True, converters={'setting': str.strip})\n",
    "            title_tag = '({}-{} Hz)'.format(settings_df['--fmin'], settings_df['--fmax'])\n",
    "        else:\n",
    "            print('WARNING: Settings file {} not found!'.format(config_file))\n",
    "            settings_df = None\n",
    "            title_tag = ''\n",
    "    else:\n",
    "        settings_df = None\n",
    "        title_tag = ''\n",
    "\n",
    "    return settings_df, title_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_process_xcorr(src_files, dataset, time_window, snr_threshold, save_plots=True, underlay_rcf_xcorr=False):\n",
    "    import sys\n",
    "    import time\n",
    "    import gc\n",
    "    from tqdm.auto import tqdm\n",
    "    from seismic.xcorqc.xcorr_station_clock_analysis import plot_xcorr_file_clock_analysis\n",
    "    \n",
    "    PY2 = (sys.version_info[0] == 2)\n",
    "    \n",
    "    pbar = tqdm(total=len(src_files), dynamic_ncols=True)\n",
    "    found_preexisting = False\n",
    "    failed_files = []\n",
    "    skipped_count = 0\n",
    "    success_count = 0\n",
    "    for src_file in src_files:\n",
    "        _, base_file = os.path.split(src_file)\n",
    "        pbar.set_description(base_file)\n",
    "        # Sleep to ensure progress bar is refreshed\n",
    "        time.sleep(0.2)\n",
    "\n",
    "        # Extract timestamp from nc filename if available\n",
    "        settings, title_tag = read_correlator_config(src_file)\n",
    "\n",
    "        assert os.path.exists(src_file), \"File {} not found!\".format(src_file)\n",
    "\n",
    "        try:\n",
    "            if save_plots:\n",
    "                basename, _ = os.path.splitext(src_file)\n",
    "                png_file = basename + \".png\"\n",
    "                # If png file already exists and has later timestamp than src_file, then skip it.\n",
    "                if os.path.exists(png_file):\n",
    "                    src_file_time = os.path.getmtime(src_file)\n",
    "                    png_file_time = os.path.getmtime(png_file)\n",
    "                    png_file_size = os.stat(png_file).st_size\n",
    "                    if png_file_time > src_file_time and png_file_size > 0:\n",
    "                        tqdm.write(\"PNG file {} is more recent than source file {}, skipping!\".format(\n",
    "                                   os.path.split(png_file)[1], os.path.split(src_file)[1]))\n",
    "                        found_preexisting = True\n",
    "                        skipped_count += 1\n",
    "                        pbar.update()\n",
    "                        continue\n",
    "                plot_xcorr_file_clock_analysis(src_file, dataset, time_window, snr_threshold, png_file=png_file,\n",
    "                                               show=False, underlay_rcf_xcorr=underlay_rcf_xcorr,\n",
    "                                               title_tag=title_tag, settings=settings)\n",
    "            else:\n",
    "                plot_xcorr_file_clock_analysis(src_file, dataset, time_window, snr_threshold, \n",
    "                                               underlay_rcf_xcorr=underlay_rcf_xcorr, title_tag=title_tag,\n",
    "                                               settings=settings)\n",
    "            success_count += 1\n",
    "            pbar.update()\n",
    "\n",
    "        except Exception as e:\n",
    "            tqdm.write(\"ERROR processing file {}\".format(src_file))\n",
    "            failed_files.append((src_file, str(e.message)))\n",
    "\n",
    "        # Python 2 does not handle circular references, so it helps to explicitly clean up.\n",
    "        if PY2:\n",
    "            gc.collect()\n",
    "\n",
    "    pbar.close()\n",
    "\n",
    "    if found_preexisting:\n",
    "        print(\"Some files were skipped because pre-existing matching png files were up-to-date.\\n\"\n",
    "              \"Remove png files to force regeneration.\")\n",
    "\n",
    "    return failed_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_process_folder(folder_name, dataset, time_window, snr_threshold, save_plots=True):\n",
    "    import glob\n",
    "    \n",
    "    src_files = glob.glob(os.path.join(folder_name, '*.nc'))\n",
    "    print(\"Found {} .nc files in {}\".format(len(src_files), folder_name))\n",
    "\n",
    "    failed_files = batch_process_xcorr(src_files, dataset, time_window=time_window, \n",
    "                                       snr_threshold=snr_threshold, save_plots=save_plots)\n",
    "    if failed_files:\n",
    "        print(\"The following files experienced errors:\")\n",
    "        for fname, err_msg in failed_files:\n",
    "            print(\" File: \" + fname)\n",
    "            if err_msg:\n",
    "                print(\"Error: \" + err_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NCFILE_PATH = '/g/data/ha3/am7399/shared/xcorr/AU/QIS_Warramunga'\n",
    "batch_process_folder(NCFILE_PATH, ds, time_window=600, snr_threshold=6, save_plots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NCFILE_PATH = '/home/547/am7399/am7399/shared/xcorr/7X/MAx_MAy'\n",
    "batch_process_folder(NCFILE_PATH, ds, time_window=120, snr_threshold=6, save_plots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
